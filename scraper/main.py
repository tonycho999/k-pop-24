import json
import re
import os
from news_api import NewsEngine
from naver_api import NaverManager
from database import DatabaseManager

def clean_json_text(text):
    """AI ì‘ë‹µì—ì„œ ìˆœìˆ˜ JSONë§Œ ì¶”ì¶œ"""
    # 1. ë§ˆí¬ë‹¤ìš´ ì œê±°
    match = re.search(r"```(?:json)?\s*(.*)\s*```", text, re.DOTALL)
    if match:
        text = match.group(1)
    
    # 2. ê´„í˜¸ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì¶œ
    start = text.find('{')
    end = text.rfind('}')
    
    if start != -1 and end != -1:
        return text[start:end+1]
    return text.strip()

def run_automation():
    print("ğŸš€ K-Enter24 Automation Started (English + Score Ver.)")
    
    db = DatabaseManager()
    engine = NewsEngine()
    naver = NaverManager()
    
    # ì•„ì¹´ì´ë¸Œìš© ì‹¤í–‰ ë²ˆí˜¸
    run_count = int(os.environ.get("RUN_COUNT", 0))
    
    categories = ["k-pop", "k-drama", "k-movie", "k-entertain", "k-culture"]

    for cat in categories:
        print(f"\n[{cat}] Processing...")
        try:
            # 1. Perplexity ë°ì´í„° ìˆ˜ì§‘ (í•œêµ­ ì†ŒìŠ¤)
            raw_data_str, original_query = engine.get_trends_and_rankings(cat)
            
            # 2. JSON íŒŒì‹±
            cleaned_str = clean_json_text(raw_data_str)
            if not cleaned_str or cleaned_str == "{}":
                print(f"âš ï¸ [{cat}] No data returned.")
                continue

            parsed_data = json.loads(cleaned_str)
            
            # ---------------------------------------------------
            # A. [ì‚¬ì´ë“œë°”] TOP 10 ë­í‚¹ ì €ì¥
            # ---------------------------------------------------
            top10_list = parsed_data.get('top10', [])
            if top10_list:
                print(f"  > Saving {len(top10_list)} Rankings...")
                for item in top10_list:
                    # live_rankings í…Œì´ë¸”ì— ì €ì¥ (run_count ì—†ìŒ)
                    db.save_rankings([{
                        "category": cat,
                        "rank": item.get('rank'),
                        "title": item.get('title'),
                        "meta_info": item.get('info', ''),
                        "score": 0 # ë­í‚¹ ì•„ì´í…œì€ ì ìˆ˜ 0 ì²˜ë¦¬
                    }])

            # ---------------------------------------------------
            # B. [ë©”ì¸ í”¼ë“œ] ì¸ë¬¼ ë‰´ìŠ¤ ì €ì¥ (ì˜ì–´ ê¸°ì‚¬ + ì ìˆ˜)
            # ---------------------------------------------------
            people_list = parsed_data.get('people', [])
            if people_list:
                print(f"  > Processing {len(people_list)} People Articles...")
                
                for person in people_list:
                    name = person.get('name')
                    facts = person.get('facts')
                    
                    if not name: continue

                    # Groq ê¸°ì‚¬ ìƒì„± (ì˜ì–´ + ###SCORE: XX)
                    full_text = engine.edit_with_groq(name, facts, cat)
                    
                    # --- ì ìˆ˜(Score) íŒŒì‹± ë¡œì§ ---
                    score = 70 # ê¸°ë³¸ê°’
                    final_text = full_text
                    
                    if "###SCORE:" in full_text:
                        try:
                            parts = full_text.split("###SCORE:")
                            final_text = parts[0].strip() # ì ìˆ˜ ì œì™¸í•œ ë³¸ë¬¸
                            score_str = parts[1].strip()
                            # ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: "85" ë˜ëŠ” "85/100")
                            score_match = re.search(r'\d+', score_str)
                            if score_match:
                                score = int(score_match.group())
                        except Exception as e:
                            print(f"    Warning: Score parsing failed ({e}). Defaulting to 70.")
                            score = 70
                    # ---------------------------

                    # ì œëª©ê³¼ ë³¸ë¬¸ ë¶„ë¦¬
                    lines = final_text.split('\n')
                    # ì œëª©ì—ì„œ "Headline:", "Title:" ê°™ì€ ì ‘ë‘ì–´ ì œê±°
                    raw_title = lines[0]
                    title = re.sub(r'^(Headline:|Title:|Subject:)\s*', '', raw_title, flags=re.IGNORECASE).strip()
                    summary = "\n".join(lines[1:]).strip()
                    
                    # ë„¤ì´ë²„ ì´ë¯¸ì§€ ê²€ìƒ‰ (í•œê¸€ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•´ì•¼ ì •í™•í•¨)
                    img_url = naver.get_image(name)
                    
                    # 1. ì•„ì¹´ì´ë¸Œ ì €ì¥ (run_count í¬í•¨)
                    article_data = {
                        "category": cat,
                        "keyword": name,
                        "title": title,
                        "summary": summary,
                        "link": person.get('link', ''),
                        "image_url": img_url,
                        "score": score,  # AIê°€ ë¶€ì—¬í•œ ì ìˆ˜
                        "likes": 0,
                        "query": original_query,
                        "raw_result": str(person),
                        "run_count": run_count 
                    }
                    db.save_to_archive(article_data)
                    
                    # 2. ë¼ì´ë¸Œ ë‰´ìŠ¤ ì €ì¥ (ì‹¤ì‹œê°„ ë…¸ì¶œìš©)
                    live_data = {
                        "category": article_data['category'],
                        "keyword": article_data['keyword'],
                        "title": article_data['title'],
                        "summary": article_data['summary'],
                        "link": article_data['link'],
                        "image_url": article_data['image_url'],
                        "score": score, # AIê°€ ë¶€ì—¬í•œ ì ìˆ˜ (ì •ë ¬ ê¸°ì¤€ì´ ë¨)
                        "likes": 0
                    }
                    db.save_live_news([live_data])
                    print(f"    - Updated: {name} (Score: {score})")

        except json.JSONDecodeError:
            print(f"âŒ [{cat}] JSON Parsing Error.")
        except Exception as e:
            print(f"âŒ [{cat}] Unknown Error: {e}")

if __name__ == "__main__":
    run_automation()

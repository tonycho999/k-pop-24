import os
import json
import re
import time
from chart_api import ChartEngine
from database import DatabaseManager
from supabase import create_client

def clean_json_text(text):
    if not text: return "{}"
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1: return text[start:end+1]
    return text.strip()

# Supabase ì—°ê²° ì„¤ì •
supa_url = os.environ.get("SUPABASE_URL")
supa_key = os.environ.get("SUPABASE_KEY")
supabase = create_client(supa_url, supa_key) if supa_url and supa_key else None

def get_run_count():
    if not supabase: return 0
    try:
        res = supabase.table('system_status').select('run_count').eq('id', 1).single().execute()
        return res.data['run_count'] if res.data else 0
    except: return 0

def update_run_count(current):
    if not supabase: return
    next_count = (current + 1) % 24 # 0~23 ìˆœí™˜
    try:
        supabase.table('system_status').upsert({'id': 1, 'run_count': next_count}).execute()
        print(f"ğŸ”„ Cycle Count Updated: {current} -> {next_count}")
    except Exception as e:
        print(f"âš ï¸ Failed to update run count: {e}")

def get_groq_config(run_count):
    """
    8ê°œì˜ Groq í‚¤ ì¤‘ ì´ë²ˆ ì‹œê°„ì— ì‚¬ìš©í•  í‚¤ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    ì‚¬ìš©ì ìš”ì²­: 1ë²ˆ, 5ë²ˆ í‚¤ ì‹œê°„ì¼ ë•Œ ì°¨íŠ¸ ìˆ˜ì§‘ ì‹¤í–‰.
    """
    key_idx = (run_count % 8) + 1  # 1, 2, 3, 4, 5, 6, 7, 8
    key_name = f"GROQ_API_KEY{key_idx}"
    api_key = os.environ.get(key_name)
    
    # ì°¨íŠ¸ ì‹¤í–‰ ì—¬ë¶€ (1ë²ˆ í‚¤ ë˜ëŠ” 5ë²ˆ í‚¤ì¼ ë•Œë§Œ True)
    should_run_chart = key_idx in [1, 5]
    
    return api_key, key_idx, should_run_chart

def run_automation():
    run_count = get_run_count()
    print(f"ğŸš€ [Cycle {run_count}/23] Automation Started")
    
    # 1. Groq í‚¤ ë¡œí…Œì´ì…˜ ë° ì°¨íŠ¸ ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨
    groq_api_key, key_num, is_chart_time = get_groq_config(run_count)
    print(f"ğŸ”‘ Using GROQ_API_KEY{key_num}")
    
    db = DatabaseManager()
    
    # 2. [Phase 1] ì°¨íŠ¸ ìˆ˜ì§‘ (1ë²ˆ, 5ë²ˆ í‚¤ ì‹œê°„ì¼ ë•Œë§Œ ìˆ˜í–‰)
    if is_chart_time:
        print(f"ğŸ“Š Chart Update Time! (Key #{key_num} active)")
        engine = ChartEngine()
        categories = ["k-pop", "k-drama", "k-movie", "k-entertain"]

        for cat in categories:
            print(f"[{cat}] Scraping...")
            chart_json = engine.get_top10_chart(cat, run_count)
            cleaned_chart = clean_json_text(chart_json)
            
            try:
                parsed_chart = json.loads(cleaned_chart)
                top10_list = parsed_chart.get('top10', [])
                
                if top10_list:
                    print(f"  > Saving {len(top10_list)} items to DB...")
                    db_data = []
                    for item in top10_list:
                        db_data.append({
                            "category": cat,
                            "rank": item.get('rank'),
                            "title": item.get('title'),
                            "meta_info": item.get('info', ''),
                            "score": 100
                        })
                    db.save_rankings(db_data)
                else:
                    print(f"  > âš ï¸ No data for {cat}")
            except Exception as e:
                print(f"  > âŒ Error: {e}")
    else:
        print(f"â­ï¸ Skipping Chart Scrape (Key #{key_num} is for News only)")

    # 3. [Phase 2] ê¸°ì‚¬ ì‘ì„± (news_api.py ì—°ë™ êµ¬ì—­)
    # ì´ ì„¹ì…˜ì€ ë§¤ì‹œê°„(Every Cycle) ì‹¤í–‰ë©ë‹ˆë‹¤.
    print(f"ğŸ“ Starting News Article Generation with Key #{key_num}...")
    # TODO: news_api.process(groq_api_key) í˜¸ì¶œ ì˜ˆì •

    update_run_count(run_count)

if __name__ == "__main__":
    run_automation()

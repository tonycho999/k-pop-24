import time
from datetime import datetime
from config import CATEGORY_MAP
import crawler
import ai_engine
import repository

# [ì¶”ê°€] ë°©ê¸ˆ ë§Œë“  ìˆœìœ„ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from update_rankings import update_rankings 

def run():
    print("ğŸš€ 7ë‹¨ê³„ ë§ˆìŠ¤í„° ì—”ì§„ ê°€ë™ (ëª¨ë“ˆí™” ë²„ì „)...")
    
    for category, keywords in CATEGORY_MAP.items():
        print(f"ğŸ“‚ {category.upper()} ë¶€ë¬¸ ì²˜ë¦¬ ì¤‘...")

        # 1. ìˆ˜ì§‘
        raw_news = []
        for kw in keywords: 
            raw_news.extend(crawler.get_naver_api_news(kw))
        
        # 2. ì¤‘ë³µ ì œê±°
        existing_links = repository.get_existing_links(category)
        
        new_candidate_news = []
        seen_links = set()
        for n in raw_news:
            if n['link'] not in existing_links and n['link'] not in seen_links:
                new_candidate_news.append(n)
                seen_links.add(n['link'])
        
        print(f"   ğŸ” ìˆ˜ì§‘: {len(raw_news)}ê°œ -> ê¸°ì¡´ DB ì¤‘ë³µ ì œì™¸: {len(new_candidate_news)}ê°œ")

        # 3. AI ì„ ë³„
        selected = ai_engine.ai_category_editor(category, new_candidate_news)
        print(f"   ã„´ AI ì„ ë³„ ì™„ë£Œ: {len(selected)}ê°œ")

        # 4. ì‹ ê·œ ë‰´ìŠ¤ ë°ì´í„° ìƒì„± ë° ì €ì¥
        if selected:
            new_data_list = []
            for i, art in enumerate(selected):
                idx = art.get('original_index')
                if idx is None or idx >= len(new_candidate_news): continue
                
                orig = new_candidate_news[idx]
                img = crawler.get_article_image(orig['link']) or f"https://placehold.co/600x400/111/cyan?text={category}"

                new_data_list.append({
                    "rank": art.get('rank', 99), 
                    "category": category, 
                    "title": art.get('eng_title', orig['title']),
                    "summary": art.get('summary', 'Detailed summary not available.'), 
                    "link": orig['link'], 
                    "image_url": img,
                    "score": art.get('score', 5.0), 
                    "likes": 0, 
                    "dislikes": 0, 
                    "created_at": datetime.now().isoformat(),
                    "published_at": orig.get('published_at', datetime.now()).isoformat()
                })
            
            # DB ì €ì¥ (Repositoryì—ê²Œ ìœ„ì„)
            repository.save_news(new_data_list)

        # 5. ìŠ¬ë¡¯ ê´€ë¦¬ (30ê°œ ìœ ì§€)
        repository.manage_slots(category)

    # [ë§ˆì§€ë§‰ ë‹¨ê³„] ì•„ì¹´ì´ë¹™ ë° í‚¤ì›Œë“œ ë¶„ì„
    repository.archive_top_articles() 
    
    print("ğŸ“Š AI í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘...")
    titles = repository.get_recent_titles()
    if titles:
        keywords = ai_engine.ai_analyze_keywords(titles)
        if keywords:
            print(f"   ğŸ”¥ AI ì¶”ì¶œ íŠ¸ë Œë“œ: {[k.get('keyword') for k in keywords[:3]]}...")
            repository.update_keywords_db(keywords)
    
    print(f"ğŸ‰ ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì‘ì—… ì™„ë£Œ.")

def main():
    print("ğŸš€ K-Enter AI News Bot Started...")
    
    while True:
        try:
            print("\n--- [Cycle Start] ---")
            
            # [1] ìˆœìœ„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤í–‰ (ì‚¬ì´ë“œë°”ìš©)
            print("ğŸ“Š Updating Trend Rankings...")
            update_rankings() 
            
            # [2] ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ìš”ì•½ ë¡œì§ ì‹¤í–‰
            print("ğŸ“° Fetching & Processing News...")
            run()
            
            print("âœ… Cycle Completed. Waiting for next run...")
            
        except Exception as e:
            print(f"âŒ Error in main loop: {e}")
            
        # ëŒ€ê¸° ì‹œê°„ (30ë¶„ = 1800ì´ˆ)
        time.sleep(1800) 

if __name__ == "__main__":
    main()

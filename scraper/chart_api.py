import asyncio
import os
from playwright.async_api import async_playwright

class ChartEngine:
    def __init__(self):
        # ì´ì œ Perplexityë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ API ì„¤ì •ì€ ìƒëµí•˜ê±°ë‚˜ ìœ ì§€í•´ë„ ë©ë‹ˆë‹¤.
        pass

    def get_top10_chart(self, category):
        """
        Playwright ë´‡ì„ ì‚¬ìš©í•˜ì—¬ ë©œë¡ ì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        (í˜„ì¬ K-POP ì¹´í…Œê³ ë¦¬ë§Œ ë´‡ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ ì„¤ì •)
        """
        if category == "k-pop":
            print(f"ğŸš€ [Bot] Scraping Melon Top 10 Chart directly...")
            return asyncio.run(self._scrape_melon())
        else:
            # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” í˜„ì¬ ë¹ˆ ë°ì´í„° ë°˜í™˜ (í•„ìš”ì‹œ ì¶”ê°€ í™•ì¥ ê°€ëŠ¥)
            return '{"top10": []}'

    async def _scrape_melon(self):
        async with async_playwright() as p:
            # GitHub Actions í™˜ê²½ì—ì„œëŠ” headless=True í•„ìˆ˜
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                # ë©œë¡  ì°¨íŠ¸ ì ‘ì†
                await page.goto("https://www.melon.com/chart/index.htm", timeout=60000)
                await page.wait_for_selector(".lst50", timeout=10000)

                top10_data = []
                # ìƒìœ„ 10ê°œ í–‰ ì¶”ì¶œ
                rows = await page.query_selector_all(".lst50")
                for i, row in enumerate(rows[:10]):
                    title_el = await row.query_selector(".rank01 a")
                    artist_el = await row.query_selector(".rank02 a")
                    
                    title = (await title_el.inner_text()).strip()
                    artist = (await artist_el.inner_text()).strip()
                    
                    top10_data.append({
                        "rank": i + 1,
                        "title": title,
                        "info": artist  # ë©”íƒ€ ì •ë³´ì— ê°€ìˆ˜ëª… ì €ì¥
                    })

                await browser.close()
                # ê¸°ì¡´ main.pyì™€ í˜¸í™˜ë˜ë„ë¡ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
                return json.dumps({"top10": top10_data}, ensure_ascii=False)
            
            except Exception as e:
                print(f"âŒ Bot Scraping Error: {e}")
                await browser.close()
                return '{"top10": []}'

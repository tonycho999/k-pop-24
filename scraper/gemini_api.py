import os
import requests
import time
import re
from dotenv import load_dotenv

load_dotenv(os.path.join(os.path.dirname(__file__), '../.env'))
API_KEY = os.getenv("GOOGLE_API_KEY")

def ask_gemini_with_search_debug(prompt):
    if not API_KEY: return None, "API_KEY_MISSING"

    # [ìˆ˜ì •] ê°€ì¥ ì•ˆì •ì ì¸ v1 ë²„ì „ ì£¼ì†Œë¡œ ë³€ê²½
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key={API_KEY.strip()}"
    headers = {"Content-Type": "application/json"}
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "tools": [{"google_search_retrieval": {}}], # êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 2048 # ì‘ë‹µ ê¸¸ì´ ë³´ì¥
        }
    }

    for attempt in range(2): # ì¬ì‹œë„ íšŸìˆ˜
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=120)
            
            # 404 ì—ëŸ¬ ë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì›ì¸ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ë¡œê·¸ ê°•í™”
            if resp.status_code != 200:
                error_detail = f"HTTP_{resp.status_code}: {resp.text}"
                print(f"ğŸš¨ API í˜¸ì¶œ ì‹¤íŒ¨: {error_detail}")
                return None, error_detail

            res_json = resp.json()
            raw_text = res_json['candidates'][0]['content']['parts'][0]['text']
            
            # [ê¸°ì¡´ê³¼ ë™ì¼í•œ íƒœê·¸ íŒŒì‹± ë¡œì§]
            def get_content(tag, text):
                pattern = rf"(?:\*+|#+)?{tag}(?:\*+|#+)?[:\s-]*(.*?)(?=\s*(?:#+|TARGET|HEADLINE|CONTENT|RANKINGS)|$)"
                match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
                return match.group(1).strip() if match else None

            parsed = {
                'target_kr': get_content("TARGET_KR", raw_text),
                'target_en': get_content("TARGET_EN", raw_text),
                'headline': get_content("HEADLINE", raw_text),
                'content': get_content("CONTENT", raw_text),
                'raw_rankings': get_content("RANKINGS", raw_text)
            }

            if parsed['headline'] and parsed['content']:
                return parsed, raw_text
            return None, raw_text

        except Exception as e:
            time.sleep(5)
            last_err = f"EXCEPTION: {str(e)}"
            
    return None, last_err

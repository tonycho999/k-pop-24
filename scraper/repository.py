from datetime import datetime, timedelta
from dateutil.parser import isoparse
from config import supabase, CATEGORY_MAP

def get_existing_links(category):
    """ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ë§í¬ ì¡°íšŒ"""
    res = supabase.table("live_news").select("link").eq("category", category).execute()
    return {item['link'] for item in res.data}

def save_news(news_list):
    """
    ë‰´ìŠ¤ ì €ì¥: 
    1. ì¤‘ë³µ ê¸°ì‚¬ ì œê±° (ë§í¬ ê¸°ì¤€)
    2. ì ìˆ˜ 4.0ì  ë¯¸ë§Œ ì œê±°
    3. [NEW] ì¤‘ë³µ ì´ë¯¸ì§€ ì œê±° (ì‹œê°ì  ë‹¤ì–‘ì„± í™•ë³´)
    """
    if not news_list: return
    
    seen_links = set()
    seen_images = set() # [ì¶”ê°€] ì´ë¯¸ ë“±ë¡ëœ ì´ë¯¸ì§€ URL ì¶”ì ìš©
    unique_list = []
    
    # DBì— ì´ë¯¸ ì €ì¥ëœ ì´ë¯¸ì§€ë“¤ë„ í™•ì¸í•˜ë©´ ì¢‹ê² ì§€ë§Œ, 
    # ì„±ëŠ¥ì„ ìœ„í•´ í˜„ì¬ ìˆ˜ì§‘ëœ ë°°ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì´ë¯¸ì§€ë¥¼ ê±¸ëŸ¬ëƒ…ë‹ˆë‹¤.
    
    for item in news_list:
        # [ê·œì¹™ 1] ì ìˆ˜ 4.0 ë¯¸ë§Œì€ ì €ì¥ ì•ˆ í•¨
        if item.get('score', 0) < 4.0:
            continue

        link = item['link']
        img_url = item.get('image_url', '')

        # [ê·œì¹™ 2] ë§í¬ ì¤‘ë³µ ì²´í¬
        if link in seen_links:
            continue

        # [ê·œì¹™ 3] ì´ë¯¸ì§€ ì¤‘ë³µ ì²´í¬ (ë‹¤ì–‘ì„± í™•ë³´)
        # ì´ë¯¸ì§€ê°€ ì—†ê±°ë‚˜(ë¹ˆ ë¬¸ìì—´), í”Œë ˆì´ìŠ¤í™€ë”ì¸ ê²½ìš°ëŠ” ì œì™¸í•˜ê³  ì²´í¬
        if img_url and "placehold.co" not in img_url:
            if img_url in seen_images:
                # ì´ë¯¸ ê°™ì€ ì‚¬ì§„ì„ ì“°ëŠ” ê¸°ì‚¬ê°€ ë¦¬ìŠ¤íŠ¸ì— ìˆë‹¤ë©´ ì´ ê¸°ì‚¬ëŠ” ê±´ë„ˆëœ€
                continue
            seen_images.add(img_url)

        # í†µê³¼ëœ ê¸°ì‚¬ ì¶”ê°€
        unique_list.append(item)
        seen_links.add(link)
            
    if not unique_list:
        print("   â„¹ï¸ ì €ì¥í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤ (ì ìˆ˜ ë¯¸ë‹¬, ì¤‘ë³µ ë§í¬, ë˜ëŠ” ì¤‘ë³µ ì´ë¯¸ì§€).")
        return

    try:
        supabase.table("live_news").upsert(unique_list, on_conflict="link").execute()
        print(f"   âœ… ì‹ ê·œ {len(unique_list)}ê°œ DB ì €ì¥ ì™„ë£Œ (ì´ë¯¸ì§€ ì¤‘ë³µ ì œê±°ë¨).")
    except Exception as e:
        print(f"   âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def manage_slots(category):
    """
    [ìŠ¬ë¡¯ ê´€ë¦¬] 30ê°œ ìœ ì§€ ë¡œì§
    - 30ê°œê°€ ë„˜ìœ¼ë©´ ì˜¤ë˜ëœ ê²ƒ(24ì‹œê°„+) ì‚­ì œ
    - ê·¸ë˜ë„ ë„˜ìœ¼ë©´ ì ìˆ˜ ë‚®ì€ ìˆœ ì‚­ì œ
    - ë‚¨ì€ ê¸°ì‚¬ë“¤ì˜ ë­í‚¹(Rank) ì—…ë°ì´íŠ¸ (ì°¸ê³ ìš©)
    """
    res = supabase.table("live_news").select("*").eq("category", category).execute()
    all_articles = res.data
    total_count = len(all_articles)
    
    print(f"   ğŸ“Š {category.upper()}: í˜„ì¬ {total_count}ê°œ (ëª©í‘œ: 30ê°œ)")

    if total_count <= 30:
        _update_rankings(all_articles)
        return

    # --- ì‚­ì œ ë¡œì§ ---
    delete_ids = []
    now = datetime.now()
    threshold = now - timedelta(hours=24) 
    
    # ì‹œê°„ìˆœ ì •ë ¬
    try: 
        all_articles.sort(key=lambda x: isoparse(x['created_at']).replace(tzinfo=None))
    except: pass

    remaining_count = total_count
    
    # 1. 24ì‹œê°„ ì§€ë‚œ ê¸°ì‚¬ ìš°ì„  ì‚­ì œ
    for art in all_articles:
        if remaining_count <= 30: break
        
        try: art_date = isoparse(art['created_at']).replace(tzinfo=None)
        except: art_date = datetime(2000, 1, 1)

        if art_date < threshold:
            delete_ids.append(art['id'])
            remaining_count -= 1

    # 2. ê·¸ë˜ë„ ë§ìœ¼ë©´ ì ìˆ˜ ë‚®ì€ ìˆœ ì‚­ì œ
    if remaining_count > 30:
        survivors = [a for a in all_articles if a['id'] not in delete_ids]
        survivors.sort(key=lambda x: x.get('score', 0)) # ì˜¤ë¦„ì°¨ìˆœ (ë‚®ì€ ì ìˆ˜ ë¨¼ì €)
        
        for art in survivors:
            if remaining_count <= 30: break
            delete_ids.append(art['id'])
            remaining_count -= 1

    if delete_ids:
        supabase.table("live_news").delete().in_("id", delete_ids).execute()
        print(f"   ğŸ§¹ ê³µê°„ í™•ë³´: {len(delete_ids)}ê°œ ì‚­ì œ ì™„ë£Œ.")
    
    # ë‚¨ì€ ê¸°ì‚¬ ë­í‚¹ ì¬ì •ë ¬
    final_survivors = [a for a in all_articles if a['id'] not in delete_ids]
    _update_rankings(final_survivors)

def _update_rankings(articles):
    """ë‚¨ì€ ê¸°ì‚¬ ì ìˆ˜ìˆœ ì •ë ¬ í›„ Rank ì—…ë°ì´íŠ¸"""
    if not articles: return

    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
    articles.sort(key=lambda x: x.get('score', 0), reverse=True)
    
    updates = []
    for i, art in enumerate(articles):
        new_rank = i + 1
        if art.get('rank') != new_rank:
            updates.append({"id": art['id'], "rank": new_rank})
            
    if updates:
        try:
            supabase.table("live_news").upsert(updates).execute()
        except: pass

def archive_top_articles():
    """
    [ìˆ˜ì •ë¨] ë­í¬ ë¬´ì‹œ -> ì ìˆ˜(Score) 7.0 ì´ìƒì¸ ê¸°ì‚¬ ë¬´ì¡°ê±´ ì•„ì¹´ì´ë¹™
    """
    print("ğŸ—„ï¸ ê³ ë“ì (7.0+) ê¸°ì‚¬ ì•„ì¹´ì´ë¹™ ì²´í¬...")
    
    try:
        # ì¹´í…Œê³ ë¦¬ êµ¬ë¶„ ì—†ì´ 7.0ì  ì´ìƒ ì¡°íšŒ
        res = supabase.table("live_news")\
            .select("*")\
            .gte("score", 7.0)\
            .execute()
        
        high_score_articles = res.data
        
        if high_score_articles:
            archive_data = []
            for art in high_score_articles:
                archive_data.append({
                    "created_at": art['created_at'],
                    "category": art['category'],
                    "title": art['title'],
                    "summary": art['summary'],
                    "image_url": art['image_url'],
                    "original_link": art['link'],  # live_newsì˜ link -> search_archiveì˜ original_link
                    "score": art['score'],
                    "rank": 0 # ë­í¬ëŠ” ì´ì œ ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ 0 ì²˜ë¦¬
                })
            
            # original_link ê¸°ì¤€ìœ¼ë¡œ upsert (ì¤‘ë³µ ë°©ì§€)
            supabase.table("search_archive").upsert(archive_data, on_conflict="original_link").execute()
            print(f"   ğŸ’¾ ì´ {len(archive_data)}ê°œì˜ ê³ ë“ì  ê¸°ì‚¬(7.0+) ì•„ì¹´ì´ë¸Œ ì €ì¥ ì™„ë£Œ.")
        else:
            print("   â„¹ï¸ ì €ì¥í•  ê³ ë“ì (7.0 ì´ìƒ) ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"   âš ï¸ ì•„ì¹´ì´ë¸Œ ì €ì¥ ì‹¤íŒ¨: {e}")

def update_keywords_db(keywords):
    if not keywords: return
    try:
        supabase.table("trending_keywords").delete().neq("id", 0).execute()
    except: pass 
    
    insert_data = []
    for i, item in enumerate(keywords):
        insert_data.append({
            "keyword": item.get('keyword'),
            "count": item.get('count', 0),
            "rank": item.get('rank', i + 1),
            "updated_at": datetime.now().isoformat()
        })
    
    if insert_data:
        try:
            supabase.table("trending_keywords").insert(insert_data).execute()
            print("   âœ… í‚¤ì›Œë“œ ë­í‚¹ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
        except: pass

def get_recent_titles(limit=100):
    res = supabase.table("live_news").select("title").order("created_at", desc=True).limit(limit).execute()
    return [item['title'] for item in res.data]

# scraper/naver_api.py
import os
import time
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv(os.path.join(os.path.dirname(__file__), '../.env'))
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# [ìˆ˜ì •] í•¨ìˆ˜ ì •ì˜ì— sort='sim' ì¸ìë¥¼ ì¶”ê°€í•˜ì—¬ 
# ì¸ìê°€ ì „ë‹¬ë˜ì§€ ì•Šì„ ë•ŒëŠ” ì •í™•ë„ìˆœ(sim), ì „ë‹¬ë  ë•ŒëŠ” ìµœì‹ ìˆœ(date)ìœ¼ë¡œ ì‘ë™í•˜ê²Œ í•©ë‹ˆë‹¤.
def search_news_api(keyword, display=10, sort='sim'):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API"""
    if not CLIENT_ID or not CLIENT_SECRET:
        print(f"   ğŸš¨ [Naver API Error] Client ID or Secret is MISSING.")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    
    headers = {
        "X-Naver-Client-Id": CLIENT_ID.strip(), 
        "X-Naver-Client-Secret": CLIENT_SECRET.strip()
    }
    
    params = {
        "query": keyword, 
        "display": display, 
        "sort": sort  # ì—¬ê¸°ì„œ ì¸ìë¡œ ë°›ì€ sort ê°’ì„ ë„¤ì´ë²„ APIì— ì „ë‹¬í•©ë‹ˆë‹¤.
    }

    try:
        resp = requests.get(url, headers=headers, params=params, timeout=5)
        
        if resp.status_code == 200:
            items = resp.json().get('items', [])
            return items
        else:
            print(f"   ğŸš¨ [Naver API Fail] Status: {resp.status_code}")
            return []
            
    except Exception as e:
        print(f"   ğŸš¨ [Naver Connection Error] {e}")
        return []

def crawl_article(url):
    """ë‰´ìŠ¤ ë³¸ë¬¸ ë° ì´ë¯¸ì§€ ì¶”ì¶œ"""
    if "news.naver.com" not in url:
        return {"text": "", "image": ""}

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    try:
        time.sleep(0.3) 
        resp = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(resp.text, 'html.parser')

        content = ""
        # ì£¼ìš” ë‰´ìŠ¤ ë³¸ë¬¸ ì…€ë ‰í„°
        for selector in ["#dic_area", "#articeBody", "#newsEndContents", ".go_trans._article_content"]:
            el = soup.select_one(selector)
            if el:
                for tag in el(['script', 'style', 'a', 'iframe', 'span']):
                    tag.decompose()
                content = el.get_text(strip=True)
                break
        
        image_url = ""
        og_img = soup.select_one('meta[property="og:image"]')
        if og_img:
            image_url = og_img.get('content', '')

        return {"text": content, "image": image_url}

    except Exception:
        return {"text": "", "image": ""}
